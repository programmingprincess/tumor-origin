yhat = predict(smsNB,smsTest)
ctab = table(yhat,smsTesty)
ctab
misclass = (sum(ctab)-sum(diag(ctab)))/sum(ctab) perspam = ctab[2,2]/sum(ctab[,2]) cat("misclass,perspam: ", misclass,perspam,"\n")
misclass = (sum(ctab)-sum(diag(ctab)))/sum(ctab) perspam = ctab[2,2]/sum(ctab[,2]) cat("misclass,perspam: ", misclass,perspam,"\n")
misclass = (sum(ctab)-sum(diag(ctab)))/sum(ctab)
perspam = ctab[2,2]/sum(ctab[,2])
cat("misclass,perspam: ", misclass,perspam,"\n")
smsNB = naiveBayes(smsTrain, smsTrainy, laplace=-2)
#pred and misclass
yhat = predict(smsNB,smsTest)
ctab = table(yhat,smsTesty)
ctab
cat("misclass,perspam: ", misclass,perspam,"\n")
perspam = ctab[2,2]/sum(ctab[,2])
misclass = (sum(ctab)-sum(diag(ctab)))/sum(ctab)
cat("misclass,perspam: ", misclass,perspam,"\n")
smsNB = naiveBayes(smsTrain, smsTrainy, laplace=-3)
#pred and misclass
yhat = predict(smsNB,smsTest)
ctab = table(yhat,smsTesty)
ctab
perspam = ctab[2,2]/sum(ctab[,2])
misclass = (sum(ctab)-sum(diag(ctab)))/sum(ctab)
cat("misclass,perspam: ", misclass,perspam,"\n")
smsNB = naiveBayes(smsTrain, smsTrainy, laplace=1)
#pred and misclass
yhat = predict(smsNB,smsTest)
ctab = table(yhat,smsTesty)
ctab
cat("misclass,perspam: ", misclass,perspam,"\n")
misclass = (sum(ctab)-sum(diag(ctab)))/sum(ctab)
misclass = (sum(ctab)-sum(diag(ctab)))/sum(ctab)
perspam = ctab[2,2]/sum(ctab[,2])
cat("misclass,perspam: ", misclass,perspam,"\n")
install.packages("h2o")
library(kknn)
install.packages(kknn)
install.packages("kknn")
library(kknn)
source("http://www.rob-mcculloch.org/2018_ml/webpage/R/docv.R")
carData = read.csv("http://www.rob-mcculloch.org/data/susedcars.csv", stringsAsFactors = FALSE)
dim(carData)
ls()
attach(carData)
ls(pos = 1)
ls(pos = 2)
plot(mileage,price,xlab="mileage",ylab="price")
#Linear Regression Fit
linReg = lm(price~mileage,carData)
print(summary(linReg))
abline(linReg$coef,col="red",lwd=4)
names(linReg)
cor(linReg$fitted.values,linReg$residuals)
#KNN fit with k=50 because it looked the sexiest
train = data.frame(mileage,price)
test = data.frame(mileage = sort(mileage))
kf50 = kknn(price~mileage,train,test,k=50,kernel = "rectangular")
lines(test$mileage,kf50$fitted.values,col="blue",lwd=2)
#k=500 looks too flat
kf500 = kknn(price~mileage,train,test,k=500,kernel = "rectangular")
lines(test$mileage,kf500$fitted.values,col="green",lwd=2)
#k=5 looks too volatile
kf5 = kknn(price~mileage,train,test,k=5,kernel = "rectangular")
lines(test$mileage,kf5$fitted.values,col="magenta",lwd=2)
#legend for all of the lines
legend("topright",legend=c("lin","knn5","knn50","knn200"),
col=c("red","blue","green","magenta"),lty=c(1,1,1,1))
#Knn50 predicting price of 100,000 mile car
pricePredict = data.frame(mileage=100000)
k50 = kknn(price~mileage,train,pricePredict,k=50,kernel="rectangular")
cat("kNN50: The predicted price of a 100,000 mile car is ",k50$fitted,"\n")
cat("kNN50: The predicted price of a 100,000 mile car is ",k50$fitted,"\n")
points(100000,k50$fitted,pch=10,cex=10,col="black")
#Linear Regression predicting price of 100,000 mile car
linPredict =  predict(linReg,pricePredict)
cat("Linear: The predicted price of a 100,000 mile car is ",linPredict,"\n")
#Doing 5-fold Cross validation
set.seed(99)
kv = 2:100
cv = docvknn(matrix(mileage,ncol=1),price,kv,nfold=5)
kbest = kv[which.min(cv)]
cat("The best k is: ",kbest,"\n")
kf22 = kknn(price~mileage,train,test,k=22,kernel = "rectangular")
lines(test$mileage,kf22$fitted.values,col="pink",lwd=2)
#legend for all of the lines
legend("topright",legend=c("lin","knn5","knn50","knn200"),
col=c("red","magenta","blue","green"),lty=c(1,1,1,1))
#Linear Regression Fit
linReg = lm(price~mileage,carData)
print(summary(linReg))
library(kknn)
source("http://www.rob-mcculloch.org/2018_ml/webpage/R/docv.R")
carData = read.csv("http://www.rob-mcculloch.org/data/susedcars.csv", stringsAsFactors = FALSE)
dim(carData)
ls()
attach(carData)
ls(pos = 1)
ls(pos = 2)
plot(mileage,price,xlab="mileage",ylab="price")
#Linear Regression Fit
linReg = lm(price~mileage,carData)
print(summary(linReg))
abline(linReg$coef,col="red",lwd=4)
names(linReg)
cor(linReg$fitted.values,linReg$residuals)
#KNN fit with k=50 because it looked the sexiest
train = data.frame(mileage,price)
test = data.frame(mileage = sort(mileage))
kf50 = kknn(price~mileage,train,test,k=50,kernel = "rectangular")
lines(test$mileage,kf50$fitted.values,col="blue",lwd=2)
#Doing 5-fold Cross validation
set.seed(99)
kv = 2:100
cv = docvknn(matrix(mileage,ncol=1),price,kv,nfold=5)
kbest = kv[which.min(cv)]
cat("The best k is: ",kbest,"\n")
kf22 = kknn(price~mileage,train,test,k=22,kernel = "rectangular")
lines(test$mileage,kf22$fitted.values,col="pink",lwd=2)
# How does your fit compare with the eyeball method?
# k = 22
# this one seems more fitted. more variance, less bias
points(100000,kf22$fitted,pch=10,cex=10,col="black")
cat("kNN22: The predicted price of a 100,000 mile car is ",k22$fitted,"\n")
lines(test$mileage,kf22$fitted.values,col="pink",lwd=2)
cat("kNN22: The predicted price of a 100,000 mile car is ",kf22$fitted,"\n")
kf22 = kknn(price~mileage,train,pricePredict,k=22,kernel = "rectangular")
lines(test$mileage,kf22$fitted.values,col="pink",lwd=2)
cat("kNN22: The predicted price of a 100,000 mile car is ",kf22$fitted,"\n")
cat("The best k is: ",kbest,"\n")
kf22 = kknn(price~mileage,train,test,k=22,kernel = "rectangular")
lines(test$mileage,kf22$fitted.values,col="pink",lwd=2)
kf22 = kknn(price~mileage,train,pricePredict,k=22,kernel = "rectangular")
cat("kNN22: The predicted price of a 100,000 mile car is ",kf22$fitted,"\n")
cat carData
cat (carData)
ls carData
ls (carData)
x = cbind(carData$mileage, carData$year)
colnames(x) = c("mileage", "year")
y = Boston$price
y = carData$price
mmsc=function(x) {return((x-min(x))/(max(x)-min(x)))}
xs = apply(x,2,mmsc) #apply scaling function to each column of x
#plot y vs each x
par(mfrow=c(1,2)) #two plot frames
plot(x[,1],y,xlab="lstat",ylab="medv")
plot(x[,2],y,xlab="indus",ylab="medv")
#run cross val once
par(mfrow=c(1,1))
set.seed(99)
kv = 2:20 #k values to try
n = length(y)
cvtemp = docvknn(xs,y,kv,nfold=10)
cvtemp = sqrt(cvtemp/n) #docvknn returns sum of squares
plot(kv,cvtemp)
#run cross val several times
set.seed(99)
cvmean = rep(0,length(kv)) #will keep average rmse here
ndocv = 50 #number of CV splits to try
n=length(y)
cvmat = matrix(0,length(kv),ndocv) #keep results for each split
for(i in 1:ndocv) {
cvtemp = docvknn(xs,y,kv,nfold=10)
cvmean = cvmean + cvtemp
cvmat[,i] = sqrt(cvtemp/n)
}
cvmean = cvmean/ndocv
cvmean = sqrt(cvmean/n)
plot(kv,cvmean,type="n",ylim=range(cvmat),xlab="k",cex.lab=1.5)
for(i in 1:ndocv) lines(kv,cvmat[,i],col=i,lty=3) #plot each result
lines(kv,cvmean,type="b",col="black",lwd=5) #plot average result
#refit using all the data and k=5
ddf = data.frame(y,xs)
near5 = kknn(y~.,ddf,ddf,k=5,kernel = "rectangular")
lmf = lm(y~.,ddf)
fmat = cbind(y,near5$fitted,lmf$fitted)
colnames(fmat)=c("y","kNN5","linear")
pairs(fmat)
print(cor(fmat))
#predict price of house in place with lstat=10, indus=11.
x1=10; x2=11
x1s = (x1-min(x[,1]))/(max(x[,1])-min(x[,1]))
x2s = (x2-min(x[,2]))/(max(x[,2])-min(x[,2]))
near = kknn(y~.,ddf,data.frame(lstat=x1s,indus=x2s),k=5,kernel = "rectangular")
cat("knn predicted value: ",near$fitted,"\n")
#what does a linear model predict?
print(predict(lmf,data.frame(lstat=x1s,indus=x2s)))
#let’s check we did the scaling right
lmtemp = lm(medv~lstat+indus,Boston)
#let’s check we did the scaling right
lmtemp = lm(medv~lstat+indus,carData)
x2s = (x2-min(x[,2]))/(max(x[,2])-min(x[,2]))
near = kknn(y~.,ddf,data.frame(lstat=x1s,indus=x2s),k=5,kernel = "rectangular")
cat("knn predicted value: ",near$fitted,"\n")
#what does a linear model predict?
print(predict(lmf,data.frame(lstat=x1s,indus=x2s)))
#let’s check we did the scaling right
lmtemp = lm(medv~lstat+indus,carData)
plot(kv,cvmean,type="n",ylim=range(cvmat),xlab="k",cex.lab=1.5)
for(i in 1:ndocv) lines(kv,cvmat[,i],col=i,lty=3) #plot each result
lines(kv,cvmean,type="b",col="black",lwd=5) #plot average result
cvmean = cvmean/ndocv
cvmean = sqrt(cvmean/n)
kbesttemp = kv[which.min(cvmean)]
cat("The best k is: ",kbesttemp,"\n")
install.packages("MASS")
#get the Boston data and needed libraries
library(kknn)
library(MASS)
source("docv.R") #we’ll use Rob’s code for cross-val with kNN
#get variables we want
x = cbind(Boston$lstat,Boston$indus)
colnames(x) = c("lstat","indus")
y = Boston$medv
mmsc=function(x) {return((x-min(x))/(max(x)-min(x)))}
xs = apply(x,2,mmsc) #apply scaling function to each column of x
#plot y vs each x
par(mfrow=c(1,2)) #two plot frames
plot(x[,1],y,xlab="lstat",ylab="medv")
plot(x[,2],y,xlab="indus",ylab="medv")
#run cross val once
par(mfrow=c(1,1))
set.seed(99)
kv = 2:20 #k values to try
n = length(y)
cvtemp = docvknn(xs,y,kv,nfold=10)
cvtemp = sqrt(cvtemp/n) #docvknn returns sum of squares
plot(kv,cvtemp)
#run cross val several times
set.seed(99)
cvmean = rep(0,length(kv)) #will keep average rmse here
ndocv = 50 #number of CV splits to try
n=length(y)
cvmat = matrix(0,length(kv),ndocv) #keep results for each split
for(i in 1:ndocv) {
cvtemp = docvknn(xs,y,kv,nfold=10)
cvmean = cvmean + cvtemp
cvmat[,i] = sqrt(cvtemp/n)
}
cvmean = cvmean/ndocv
cvmean = sqrt(cvmean/n)
plot(kv,cvmean,type="n",ylim=range(cvmat),xlab="k",cex.lab=1.5)
for(i in 1:ndocv) lines(kv,cvmat[,i],col=i,lty=3) #plot each result
lines(kv,cvmean,type="b",col="black",lwd=5) #plot average result
#refit using all the data and k=5
ddf = data.frame(y,xs)
x = cbind(carData$mileage, carData$year)
colnames(x) = c("mileage", "year")
y = carData$price
mmsc=function(x) {return((x-min(x))/(max(x)-min(x)))}
xs = apply(x,2,mmsc) #apply scaling function to each column of x
#plot y vs each x
par(mfrow=c(1,2)) #two plot frames
plot(x[,1],y,xlab="lstat",ylab="medv")
plot(x[,2],y,xlab="indus",ylab="medv")
#run cross val once
par(mfrow=c(1,1))
set.seed(99)
kv = 2:20 #k values to try
n = length(y)
cvtemp = docvknn(xs,y,kv,nfold=10)
cvtemp = sqrt(cvtemp/n) #docvknn returns sum of squares
plot(kv,cvtemp)
set.seed(99)
kv = 15:40 #k values to try
n = length(y)
cvtemp = docvknn(xs,y,kv,nfold=10)
cvtemp = sqrt(cvtemp/n) #docvknn returns sum of squares
plot(kv,cvtemp)
set.seed(99)
kv = 2:100 #k values to try
n = length(y)
cvtemp = docvknn(xs,y,kv,nfold=10)
cvtemp = sqrt(cvtemp/n) #docvknn returns sum of squares
plot(kv,cvtemp)
set.seed(99)
kv = 15:40 #k values to try
n = length(y)
cvtemp = docvknn(xs,y,kv,nfold=10)
cvtemp = sqrt(cvtemp/n) #docvknn returns sum of squares
plot(kv,cvtemp)
#run cross val several times
set.seed(99)
cvmean = rep(0,length(kv)) #will keep average rmse here
ndocv = 50 #number of CV splits to try
n=length(y)
cvmat = matrix(0,length(kv),ndocv) #keep results for each split
for(i in 1:ndocv) {
cvtemp = docvknn(xs,y,kv,nfold=10)
cvmean = cvmean + cvtemp
cvmat[,i] = sqrt(cvtemp/n)
}
cvmean = cvmean/ndocv
cvmean = sqrt(cvmean/n)
kbesttemp = kv[which.min(cvmean)]
cat("The best k is: ",kbesttemp,"\n")
plot(kv,cvmean,type="n",ylim=range(cvmat),xlab="k",cex.lab=1.5)
for(i in 1:ndocv) lines(kv,cvmat[,i],col=i,lty=3) #plot each result
lines(kv,cvmean,type="b",col="black",lwd=5) #plot average result
kbesttemp = kv[which.min(cvmean)]
cat("The best k is: ",kbesttemp,"\n")
#refit using all the data and k=29
ddf = data.frame(y,xs)
near5 = kknn(y~.,ddf,ddf,k=5,kernel = "rectangular")
lmf = lm(y~.,ddf)
fmat = cbind(y,near5$fitted,lmf$fitted)
colnames(fmat)=c("y","kNN5","linear")
pairs(fmat)
print(cor(fmat))
#refit using all the data and k=29
ddf = data.frame(y,xs)
near5 = kknn(y~.,ddf,ddf,k=29,kernel = "rectangular")
lmf = lm(y~.,ddf)
fmat = cbind(y,near5$fitted,lmf$fitted)
colnames(fmat)=c("y","kNN5","linear")
pairs(fmat)
print(cor(fmat))
#predict price of house in place with lstat=10, indus=11.
x1=75000; x2=2008
x1s = (x1-min(x[,1]))/(max(x[,1])-min(x[,1]))
x2s = (x2-min(x[,2]))/(max(x[,2])-min(x[,2]))
near = kknn(y~.,ddf,data.frame(lstat=x1s,indus=x2s),k=5,kernel = "rectangular")
cat("knn predicted value: ",near$fitted,"\n")
x2s = (x2-min(x[,2]))/(max(x[,2])-min(x[,2]))
near = kknn(y~.,ddf,data.frame(mileage=x1s,year=x2s),k=29,kernel = "rectangular")
cat("knn predicted value: ",near$fitted,"\n")
#predict price of house in place with lstat=10, indus=11.
x1=100000; x2=2008
x1s = (x1-min(x[,1]))/(max(x[,1])-min(x[,1]))
x2s = (x2-min(x[,2]))/(max(x[,2])-min(x[,2]))
near = kknn(y~.,ddf,data.frame(mileage=x1s,year=x2s),k=29,kernel = "rectangular")
cat("knn predicted value: ",near$fitted,"\n")
#predict price of house in place with lstat=10, indus=11.
x1=75000; x2=2002
x1s = (x1-min(x[,1]))/(max(x[,1])-min(x[,1]))
x2s = (x2-min(x[,2]))/(max(x[,2])-min(x[,2]))
near = kknn(y~.,ddf,data.frame(mileage=x1s,year=x2s),k=29,kernel = "rectangular")
cat("knn predicted value: ",near$fitted,"\n")
#predict price of house in place with lstat=10, indus=11.
x1=75000; x2=2008
x1s = (x1-min(x[,1]))/(max(x[,1])-min(x[,1]))
x2s = (x2-min(x[,2]))/(max(x[,2])-min(x[,2]))
near = kknn(y~.,ddf,data.frame(mileage=x1s,year=x2s),k=29,kernel = "rectangular")
cat("knn predicted value: ",near$fitted,"\n")
#what does a linear model predict?
print(predict(lmf,data.frame(mileage=x1s,year=x2s)))
#let’s check we did the scaling right
lmtemp = lm(medv~lstat+indus,carData)
#let’s check we did the scaling right
lmtemp = lm(medv~mileage+year,carData)
#let’s check we did the scaling right
lmtemp = lm(price~mileage+year,carData)
print(predict(lmtemp,data.frame(lstat=10,indus=11)))
#let’s check we did the scaling right
lmtemp = lm(price~mileage+year,carData)
print(predict(lmtemp,data.frame(mileage=75000,year=2008)))
#what does a linear model predict?
print(predict(lmf,data.frame(mileage=x1s,year=x2s)))
?kknn
ddf = data.frame(y,xs)
near5 = kknn(y~.,ddf,ddf,k=29,kernel = "triangular")
lmf = lm(y~.,ddf)
fmat = cbind(y,near5$fitted,lmf$fitted)
colnames(fmat)=c("y","kNN5","linear")
pairs(fmat)
print(cor(fmat))
ddf = data.frame(y,xs)
near5 = kknn(y~.,ddf,ddf,k=29,kernel = "epanechnikov")
lmf = lm(y~.,ddf)
fmat = cbind(y,near5$fitted,lmf$fitted)
colnames(fmat)=c("y","kNN5","linear")
pairs(fmat)
print(cor(fmat))
ddf = data.frame(y,xs)
near5 = kknn(y~.,ddf,ddf,k=29,kernel = "biweight")
lmf = lm(y~.,ddf)
fmat = cbind(y,near5$fitted,lmf$fitted)
colnames(fmat)=c("y","kNN5","linear")
pairs(fmat)
print(cor(fmat))
near5 = kknn(y~.,ddf,ddf,k=29,kernel = "triweight")
print(cor(fmat))
near5 = kknn(y~.,ddf,ddf,k=29,kernel = "triweight")
lmf = lm(y~.,ddf)
fmat = cbind(y,near5$fitted,lmf$fitted)
colnames(fmat)=c("y","kNN5","linear")
pairs(fmat)
print(cor(fmat))
ddf = data.frame(y,xs)
near5 = kknn(y~.,ddf,ddf,k=29,kernel = "cos")
lmf = lm(y~.,ddf)
fmat = cbind(y,near5$fitted,lmf$fitted)
colnames(fmat)=c("y","kNN5","linear")
pairs(fmat)
print(cor(fmat))
ddf = data.frame(y,xs)
near5 = kknn(y~.,ddf,ddf,k=29,kernel = "inv")
lmf = lm(y~.,ddf)
fmat = cbind(y,near5$fitted,lmf$fitted)
colnames(fmat)=c("y","kNN5","linear")
pairs(fmat)
print(cor(fmat))
ddf = data.frame(y,xs)
near5 = kknn(y~.,ddf,ddf,k=29,kernel = "gaussian")
lmf = lm(y~.,ddf)
fmat = cbind(y,near5$fitted,lmf$fitted)
colnames(fmat)=c("y","kNN5","linear")
pairs(fmat)
print(cor(fmat))
ddf = data.frame(y,xs)
near5 = kknn(y~.,ddf,ddf,k=29,kernel = "rank")
lmf = lm(y~.,ddf)
fmat = cbind(y,near5$fitted,lmf$fitted)
colnames(fmat)=c("y","kNN5","linear")
pairs(fmat)
print(cor(fmat))
ddf = data.frame(y,xs)
near5 = kknn(y~.,ddf,ddf,k=29,kernel = "optimal")
lmf = lm(y~.,ddf)
fmat = cbind(y,near5$fitted,lmf$fitted)
colnames(fmat)=c("y","kNN5","linear")
pairs(fmat)
print(cor(fmat))
ddf = data.frame(y,xs)
near5 = kknn(y~.,ddf,ddf,k=29,kernel = "rectangular")
lmf = lm(y~.,ddf)
fmat = cbind(y,near5$fitted,lmf$fitted)
colnames(fmat)=c("y","kNN5","linear")
pairs(fmat)
print(cor(fmat))
x1=75000; x2=2008
x1s = (x1-min(x[,1]))/(max(x[,1])-min(x[,1]))
x2s = (x2-min(x[,2]))/(max(x[,2])-min(x[,2]))
near = kknn(y~.,ddf,data.frame(mileage=x1s,year=x2s),k=29,kernel = "triweight")
cat("knn predicted value: ",near$fitted,"\n")
x1=75000; x2=2008
x1s = (x1-min(x[,1]))/(max(x[,1])-min(x[,1]))
x2s = (x2-min(x[,2]))/(max(x[,2])-min(x[,2]))
near = kknn(y~.,ddf,data.frame(mileage=x1s,year=x2s),k=29,kernel = "rectangular")
cat("knn predicted value: ",near$fitted,"\n")
x1=75000; x2=2008
x1s = (x1-min(x[,1]))/(max(x[,1])-min(x[,1]))
x2s = (x2-min(x[,2]))/(max(x[,2])-min(x[,2]))
near = kknn(y~.,ddf,data.frame(mileage=x1s,year=x2s),k=29,kernel = "inv")
cat("knn predicted value: ",near$fitted,"\n")
#plot y vs each x
par(mfrow=c(1,2)) #two plot frames
plot(x[,1],y,xlab="mileage",ylab="price")
plot(x[,2],y,xlab="year",ylab="price")
ls (carData)
x1=75000; x2=2008
x1s = (x1-min(x[,1]))/(max(x[,1])-min(x[,1]))
x2s = (x2-min(x[,2]))/(max(x[,2])-min(x[,2]))
near = kknn(y~.,ddf,data.frame(mileage=x1s,year=x2s),k=29,kernel = "optimal")
cat("knn predicted value: ",near$fitted,"\n")
x1=75000; x2=2008
x1s = (x1-min(x[,1]))/(max(x[,1])-min(x[,1]))
x2s = (x2-min(x[,2]))/(max(x[,2])-min(x[,2]))
near = kknn(y~.,ddf,data.frame(mileage=x1s,year=x2s),k=29,kernel = "triweight")
cat("knn predicted value: ",near$fitted,"\n")
x1=75000; x2=2008
x1s = (x1-min(x[,1]))/(max(x[,1])-min(x[,1]))
x2s = (x2-min(x[,2]))/(max(x[,2])-min(x[,2]))
near = kknn(y~.,ddf,data.frame(mileage=x1s,year=x2s),k=29,kernel = "rectangular")
cat("knn predicted value: ",near$fitted,"\n")
cat("Hello, world!")
cat("Hello, world!");
install.packages("DESeq")
source("https://bioconductor.org/biocLite.R")
biocLite("DESeq2")
vignette("DESeq2")
summary(wdbc_train[-c(1)])
knitr::opts_chunk$set(echo = TRUE)
getwd()
# wdbc = wisconsin diagnostic breast cancer
wdbc = read.csv("brcancer.csv", header=TRUE)
wdbc = wdbc[,-1] #remove ID from dataset
wdbc = wdbc[1:11] #use means only
wdbc$diagnosis2 = ifelse(wdbc$diagnosis == "M", 1, 0)
## Split into 70% train, 30% test
n = nrow(wdbc) #num "rows" in data
set.seed(30)
ntrain = floor(n*0.70) #70% for train
ii = sample(1:n,ntrain) #reorder elements randomly
wdbc_train = wdbc[ii,]
wdbc_test= wdbc[-ii,]
summary(wdbc_train[-c(1)])
yv
library(kknn)
source("http://www.rob-mcculloch.org/2018_ml/webpage/R/docv.R")
# assign variables as x and y
x=wdbc_train[,2:11] #only use mean data; 2:11
y=wdbc_train[,1]
# apply scaling function to each column of x
mmsc=function(x){return((x-min(x))/(max(x)-min(x)))}
xs = apply(x,2,mmsc) #scaling function
summary(x)
summary(y)
chol <- list.files(".", pattern="*.quantification.txt")
chol_data_list <- lapply(chol, function(x){ read.table(x, colClasses=c('character','character','numeric','numeric', 'NULL','character'), header=T)})
chol_data <- Reduce(function(x,y) {merge(x,y,by='miRNA_ID')}, chol_data_list)
chol_data
setwd("~/Desktop/tumor-origin")
chol <- list.files(".", pattern="*.quantification.txt")
chol_data_list <- lapply(chol, function(x){ read.table(x, colClasses=c('character','character','numeric','numeric', 'NULL','character'), header=T)})
chol_data <- Reduce(function(x,y) {merge(x,y,by='miRNA_ID')}, chol_data_list)
dim(chol_data)
head(chol_data,10)
chol_data_list <- lapply(chol, function(x){ read.table(x, colClasses=c('character','character','numeric','numeric', 'NULL','character'), header=T)})
chol_data_list
head(chol_data_list,10)
